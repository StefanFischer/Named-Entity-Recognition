{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "ner_1_2021.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.13"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/StefanFischer/SAKI-Project2/blob/main/ner_1_2021.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GgDUExqz5ioj"
      },
      "source": [
        "Set up Google Colab Drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3chPOl3o5MrV",
        "outputId": "b8809fb5-845c-484a-8e5a-5aca3196d0e0"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VXJqiu7P6T2p"
      },
      "source": [
        "Deep learning needs the computational power of GPUs, therefore, we run this notebook on Google Colab with GPU support.<br>\n",
        "Check RAM of GPU.<br>\n",
        "For this end, we need to install [GPUtil](https://pypi.org/project/GPUtil/)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gumhOAG16vYh",
        "outputId": "629cdb1b-c5ac-4876-bf3b-763dc8abb1a7"
      },
      "source": [
        "pip install GPUtil"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting GPUtil\n",
            "  Downloading https://files.pythonhosted.org/packages/ed/0e/5c61eedde9f6c87713e89d794f01e378cfd9565847d4576fa627d758c554/GPUtil-1.4.0.tar.gz\n",
            "Building wheels for collected packages: GPUtil\n",
            "  Building wheel for GPUtil (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for GPUtil: filename=GPUtil-1.4.0-cp37-none-any.whl size=7411 sha256=9c5a3256a9d61182f0fa892ce474e9c22b0a29e52d4f8b93690f86f2155b34db\n",
            "  Stored in directory: /root/.cache/pip/wheels/3d/77/07/80562de4bb0786e5ea186911a2c831fdd0018bda69beab71fd\n",
            "Successfully built GPUtil\n",
            "Installing collected packages: GPUtil\n",
            "Successfully installed GPUtil-1.4.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkK4Lfch6MGo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e541477d-8431-49f3-af62-2855d948eaa5"
      },
      "source": [
        "import psutil\n",
        "import humanize\n",
        "import os\n",
        "import GPUtil as GPU\n",
        "GPUs = GPU.getGPUs()\n",
        "gpu = GPUs[0]\n",
        "\n",
        "def printm():\n",
        "  process = psutil.Process(os.getpid())\n",
        "  print(\"Gen RAM Free: \" + humanize.naturalsize( psutil.virtual_memory().available ), \" I Proc size: \" + humanize.naturalsize( process.memory_info().rss))\n",
        "  print('GPU RAM Free: {0:.0f}MB | Used: {1:.0f}MB | Util {2:3.0f}% | Total {3:.0f}MB'.format(gpu.memoryFree, gpu.memoryUsed, gpu.memoryUtil*100, gpu.memoryTotal))\n",
        "\n",
        "printm()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Gen RAM Free: 12.7 GB  I Proc size: 118.9 MB\n",
            "GPU RAM Free: 11441MB | Used: 0MB | Util   0% | Total 11441MB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M3-quF-P-XXH"
      },
      "source": [
        "Change directory to \"/flair\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "BBTFZUFp_fY2",
        "outputId": "2f67413d-7fa9-43b6-ffb6-c078bdc269fa"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lRq9VJeA_sSH"
      },
      "source": [
        "So, we are currently in \"/content\""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_1VO3JH8ADUt",
        "outputId": "98f36541-a3d3-470e-9f3d-109e3a838396"
      },
      "source": [
        "for directory in os.walk( os.getcwd() ):\n",
        "\n",
        "  print( directory )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('/content', ['.config', 'gdrive', 'sample_data'], [])\n",
            "('/content/.config', ['configurations', 'logs'], ['.last_survey_prompt.yaml', 'config_sentinel', 'active_config', 'gce', '.last_opt_in_prompt.yaml', '.last_update_check.json'])\n",
            "('/content/.config/configurations', [], ['config_default'])\n",
            "('/content/.config/logs', ['2021.05.06'], [])\n",
            "('/content/.config/logs/2021.05.06', [], ['13.43.04.692209.log', '13.44.01.543195.log', '13.43.23.909017.log', '13.43.44.620859.log', '13.44.00.991142.log', '13.43.39.026092.log'])\n",
            "('/content/gdrive', ['.shortcut-targets-by-id', 'MyDrive', '.file-revisions-by-id', '.Trash'], [])\n",
            "('/content/gdrive/.shortcut-targets-by-id', [], [])\n",
            "('/content/gdrive/MyDrive', ['AI', 'Colab Notebooks', 'flair', '.ipynb_checkpoints'], ['How to get started with Drive.pdf', 'Ihre zündende Idee .gslides', 'Hochzeit.gslides', 'Leadership2.gslides', 'koreanPresentation.gslides', 'Leadership2.pdf'])\n",
            "('/content/gdrive/MyDrive/AI', [], ['mnist_test_10.csv', 'mnist_train_100.csv'])\n",
            "('/content/gdrive/MyDrive/Colab Notebooks', [], ['ner_1_2021.ipynb', 'ner_2_2021.ipynb', 'ner_3_2021 (1).ipynb', 'ner_3_2021.ipynb', 'ner_4_2021.ipynb'])\n",
            "('/content/gdrive/MyDrive/flair', ['flair_glove'], ['Entity Recognition in Resumes.json', 'training_data.csv', 'test_data.csv'])\n",
            "('/content/gdrive/MyDrive/flair/flair_glove', [], ['weights.txt', 'best-model.pt', 'dev.tsv', 'loss.tsv', 'final-model.pt', 'training.log', 'test.tsv'])\n",
            "('/content/gdrive/MyDrive/.ipynb_checkpoints', [], [])\n",
            "('/content/gdrive/.file-revisions-by-id', [], [])\n",
            "('/content/gdrive/.Trash', [], [])\n",
            "('/content/sample_data', [], ['README.md', 'anscombe.json', 'mnist_train_small.csv', 'california_housing_train.csv', 'mnist_test.csv', 'california_housing_test.csv'])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hhCgEKfqA8mU"
      },
      "source": [
        "We see in the table above, that there exists a folder \"/content/gdrive/MyDrive/flair\" into which we have loaded our data.<br>\n",
        "We now change the working directory to this directory."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LefqzTtQA229"
      },
      "source": [
        "os.chdir( \"/content/gdrive/MyDrive/flair\" ) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "r88--TlKBW9r",
        "outputId": "41282681-a70f-4031-ead8-02e6a0cf5b65"
      },
      "source": [
        "os.getcwd()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/gdrive/MyDrive/flair'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvMm_zd0Mb6k"
      },
      "source": [
        "Using the code from above, we change the current working directory to the directory, where we loaded our data to."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1KpNb75WC1RS",
        "outputId": "a530a737-6678-4705-d27d-e4846d8cc291"
      },
      "source": [
        "os.listdir( os.getcwd() )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Entity Recognition in Resumes.json',\n",
              " 'training_data.csv',\n",
              " 'test_data.csv',\n",
              " 'flair_glove']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PvSVxTV4ERCb"
      },
      "source": [
        "Install Flair"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s6UgvIiOET3h",
        "outputId": "34425d6a-2c12-49cf-9b12-f59866b5ab88"
      },
      "source": [
        "pip install flair"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting flair\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/3a/1b46a0220d6176b22bcb9336619d1731301bc2c75fa926a9ef953e6e4d58/flair-0.8.0.post1-py3-none-any.whl (284kB)\n",
            "\u001b[K     |████████████████████████████████| 286kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.7/dist-packages (from flair) (2.8.1)\n",
            "Collecting bpemb>=0.3.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f2/6f/9191b85109772636a8f8accb122900c34db26c091d2793218aa94954524c/bpemb-0.3.3-py3-none-any.whl\n",
            "Collecting transformers>=4.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d5/43/cfe4ee779bbd6a678ac6a97c5a5cdeb03c35f9eaebbb9720b036680f9a2d/transformers-4.6.1-py3-none-any.whl (2.2MB)\n",
            "\u001b[K     |████████████████████████████████| 2.3MB 3.6MB/s \n",
            "\u001b[?25hRequirement already satisfied: scikit-learn>=0.21.3 in /usr/local/lib/python3.7/dist-packages (from flair) (0.22.2.post1)\n",
            "Collecting sqlitedict>=1.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/5c/2d/b1d99e9ad157dd7de9cd0d36a8a5876b13b55e4b75f7498bc96035fb4e96/sqlitedict-1.7.0.tar.gz\n",
            "Requirement already satisfied: matplotlib>=2.2.3 in /usr/local/lib/python3.7/dist-packages (from flair) (3.2.2)\n",
            "Collecting ftfy\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/da/d215a091986e5f01b80f5145cff6f22e2dc57c6b048aab2e882a07018473/ftfy-6.0.3.tar.gz (64kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 5.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.26.0 in /usr/local/lib/python3.7/dist-packages (from flair) (4.41.1)\n",
            "Collecting sentencepiece==0.1.95\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f5/99/e0808cb947ba10f575839c43e8fafc9cc44e4a7a2c8f79c60db48220a577/sentencepiece-0.1.95-cp37-cp37m-manylinux2014_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: gensim<=3.8.3,>=3.4.0 in /usr/local/lib/python3.7/dist-packages (from flair) (3.6.0)\n",
            "Collecting segtok>=1.5.7\n",
            "  Downloading https://files.pythonhosted.org/packages/41/08/582dab5f4b1d5ca23bc6927b4bb977c8ff7f3a87a3b98844ef833e2f5623/segtok-1.5.10.tar.gz\n",
            "Requirement already satisfied: lxml in /usr/local/lib/python3.7/dist-packages (from flair) (4.2.6)\n",
            "Requirement already satisfied: hyperopt>=0.1.1 in /usr/local/lib/python3.7/dist-packages (from flair) (0.1.2)\n",
            "Collecting langdetect\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/72/a3add0e4eec4eb9e2569554f7c70f4a3c27712f40e3284d483e88094cc0e/langdetect-1.0.9.tar.gz (981kB)\n",
            "\u001b[K     |████████████████████████████████| 983kB 12.4MB/s \n",
            "\u001b[?25hCollecting janome\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a8/63/98858cbead27df7536c7e300c169da0999e9704d02220dc6700b804eeff0/Janome-0.4.1-py2.py3-none-any.whl (19.7MB)\n",
            "\u001b[K     |████████████████████████████████| 19.7MB 1.5MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading https://files.pythonhosted.org/packages/32/a1/7c5261396da23ec364e296a4fb8a1cd6a5a2ff457215c6447038f18c0309/huggingface_hub-0.0.9-py3-none-any.whl\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.7/dist-packages (from flair) (2019.12.20)\n",
            "Collecting deprecated>=1.2.4\n",
            "  Downloading https://files.pythonhosted.org/packages/fb/73/994edfcba74443146c84b91921fcc269374354118d4f452fb0c54c1cbb12/Deprecated-1.2.12-py2.py3-none-any.whl\n",
            "Collecting torch<=1.7.1,>=1.5.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/90/5d/095ddddc91c8a769a68c791c019c5793f9c4456a688ddd235d6670924ecb/torch-1.7.1-cp37-cp37m-manylinux1_x86_64.whl (776.8MB)\n",
            "\u001b[K     |████████████████████████████████| 776.8MB 24kB/s \n",
            "\u001b[?25hCollecting gdown==3.12.2\n",
            "  Downloading https://files.pythonhosted.org/packages/50/21/92c3cfe56f5c0647145c4b0083d0733dd4890a057eb100a8eeddf949ffe9/gdown-3.12.2.tar.gz\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.7/dist-packages (from flair) (0.8.9)\n",
            "Collecting konoha<5.0.0,>=4.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/71/70/48a0bd55f79c328504fe6fe7ae8ff651f77a2aadbb1911701385d9bb5ca3/konoha-4.6.5-py3-none-any.whl\n",
            "Collecting mpld3==0.3\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/95/a52d3a83d0a29ba0d6898f6727e9858fe7a43f6c2ce81a5fe7e05f0f4912/mpld3-0.3.tar.gz (788kB)\n",
            "\u001b[K     |████████████████████████████████| 798kB 29.0MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy<1.20.0 in /usr/local/lib/python3.7/dist-packages (from flair) (1.19.5)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.6.1->flair) (1.15.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from bpemb>=0.3.2->flair) (2.23.0)\n",
            "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (4.0.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/e2/df3543e8ffdab68f5acc73f613de9c2b155ac47f162e725dcac87c521c11/tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3MB 32.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (20.9)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers>=4.0.0->flair) (3.0.12)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/75/ee/67241dc87f266093c533a2d4d3d69438e57d7a90abb216fa076e7d475d4a/sacremoses-0.0.45-py3-none-any.whl (895kB)\n",
            "\u001b[K     |████████████████████████████████| 901kB 30.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.4.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.7/dist-packages (from scikit-learn>=0.21.3->flair) (1.0.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (2.4.7)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib>=2.2.3->flair) (1.3.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from ftfy->flair) (0.2.5)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim<=3.8.3,>=3.4.0->flair) (5.0.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (2.5.1)\n",
            "Requirement already satisfied: pymongo in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (3.11.4)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from hyperopt>=0.1.1->flair) (0.16.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub->flair) (3.7.4.3)\n",
            "Requirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.7/dist-packages (from deprecated>=1.2.4->flair) (1.12.1)\n",
            "Collecting overrides<4.0.0,>=3.0.0\n",
            "  Downloading https://files.pythonhosted.org/packages/ff/b1/10f69c00947518e6676bbd43e739733048de64b8dd998e9c2d5a71f44c5d/overrides-3.1.0.tar.gz\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->bpemb>=0.3.2->flair) (3.0.4)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers>=4.0.0->flair) (3.4.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers>=4.0.0->flair) (7.1.2)\n",
            "Requirement already satisfied: decorator<5,>=4.3 in /usr/local/lib/python3.7/dist-packages (from networkx->hyperopt>=0.1.1->flair) (4.4.2)\n",
            "Building wheels for collected packages: gdown\n",
            "  Building wheel for gdown (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gdown: filename=gdown-3.12.2-cp37-none-any.whl size=9693 sha256=072a46aa06cf64630a65c9dd820fe7cd6603f1d385e72b0f672292471eeddaf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/d0/d7/d9983facc6f2775411803e0e2d30ebf98efbf2fc6e57701e09\n",
            "Successfully built gdown\n",
            "Building wheels for collected packages: sqlitedict, ftfy, segtok, langdetect, mpld3, overrides\n",
            "  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sqlitedict: filename=sqlitedict-1.7.0-cp37-none-any.whl size=14376 sha256=3a308e03095f178257af70b64b0ae57ef8f0a4a34818a8a605e391b596bb7074\n",
            "  Stored in directory: /root/.cache/pip/wheels/cf/c6/4f/2c64a43f041415eb8b8740bd80e15e92f0d46c5e464d8e4b9b\n",
            "  Building wheel for ftfy (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for ftfy: filename=ftfy-6.0.3-cp37-none-any.whl size=41916 sha256=8b51dfaa57cd51591486e565eb1326e2b14918d833d4e5357b76ad5128aaf289\n",
            "  Stored in directory: /root/.cache/pip/wheels/99/2c/e6/109c8a28fef7a443f67ba58df21fe1d0067ac3322e75e6b0b7\n",
            "  Building wheel for segtok (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for segtok: filename=segtok-1.5.10-cp37-none-any.whl size=25019 sha256=533f0cc1391845d02c3441277d0e2e77503e3696e3a0c40f4a856d0b6e2c421d\n",
            "  Stored in directory: /root/.cache/pip/wheels/b4/39/f6/9ca1c5cabde964d728023b5751c3a206a5c8cc40252321fb6b\n",
            "  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for langdetect: filename=langdetect-1.0.9-cp37-none-any.whl size=993223 sha256=6bf69d5e137ac12e139672401368a8d5fbd106b1c8f8d00fbeca07a167046caf\n",
            "  Stored in directory: /root/.cache/pip/wheels/7e/18/13/038c34057808931c7ddc6c92d3aa015cf1a498df5a70268996\n",
            "  Building wheel for mpld3 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mpld3: filename=mpld3-0.3-cp37-none-any.whl size=116679 sha256=993acb1c00dcf294dddf60dcaebf53c1ea260d6be34c89a667ebc005afe93dc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/c0/47/fb/8a64f89aecfe0059830479308ad42d62e898a3e3cefdf6ba28\n",
            "  Building wheel for overrides (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for overrides: filename=overrides-3.1.0-cp37-none-any.whl size=10174 sha256=d89ffdc1130dce3b81005f5ef4028509da6b60c65452381f38516325c0cf4144\n",
            "  Stored in directory: /root/.cache/pip/wheels/5c/24/13/6ef8600e6f147c95e595f1289a86a3cc82ed65df57582c65a9\n",
            "Successfully built sqlitedict ftfy segtok langdetect mpld3 overrides\n",
            "\u001b[31mERROR: torchvision 0.9.1+cu101 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: torchtext 0.9.1 has requirement torch==1.8.1, but you'll have torch 1.7.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: transformers 4.6.1 has requirement huggingface-hub==0.0.8, but you'll have huggingface-hub 0.0.9 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: konoha 4.6.5 has requirement importlib-metadata<4.0.0,>=3.7.0, but you'll have importlib-metadata 4.0.1 which is incompatible.\u001b[0m\n",
            "\u001b[31mERROR: konoha 4.6.5 has requirement requests<3.0.0,>=2.25.1, but you'll have requests 2.23.0 which is incompatible.\u001b[0m\n",
            "Installing collected packages: sentencepiece, bpemb, tokenizers, huggingface-hub, sacremoses, transformers, sqlitedict, ftfy, segtok, langdetect, janome, deprecated, torch, gdown, overrides, konoha, mpld3, flair\n",
            "  Found existing installation: torch 1.8.1+cu101\n",
            "    Uninstalling torch-1.8.1+cu101:\n",
            "      Successfully uninstalled torch-1.8.1+cu101\n",
            "  Found existing installation: gdown 3.6.4\n",
            "    Uninstalling gdown-3.6.4:\n",
            "      Successfully uninstalled gdown-3.6.4\n",
            "Successfully installed bpemb-0.3.3 deprecated-1.2.12 flair-0.8.0.post1 ftfy-6.0.3 gdown-3.12.2 huggingface-hub-0.0.9 janome-0.4.1 konoha-4.6.5 langdetect-1.0.9 mpld3-0.3 overrides-3.1.0 sacremoses-0.0.45 segtok-1.5.10 sentencepiece-0.1.95 sqlitedict-1.7.0 tokenizers-0.10.3 torch-1.7.1 transformers-4.6.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OKbUtk3gUIUH"
      },
      "source": [
        "Import the Data Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0hwSlDozTvTu"
      },
      "source": [
        "path_to_data = os.getcwd() + '/Entity Recognition in Resumes.json'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zPPLwoi8Mb6l"
      },
      "source": [
        "__Task 1__: Complete the following code: we want to read the data from said .json-file into the list __imported_data__. Also, print the first line, so that we get an idea, what the data look like. Also, print how many resumees we got."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "StK5oNS8Uo7G",
        "outputId": "039b3d6c-577c-4507-a258-5bdb70d1cbc9"
      },
      "source": [
        "myfile = open( path_to_data, \"r\", encoding = \"utf-8\" )\n",
        "\n",
        "imported_data = []\n",
        "i = 0\n",
        "for datum in myfile:\n",
        "    \n",
        "    # TODO process data\n",
        "    imported_data.append(datum)\n",
        "\n",
        "myfile.close()\n",
        "\n",
        "# TODO print first line\n",
        "print(imported_data[0])\n",
        "\n",
        "# TODO print how many resumees were read in\n",
        "print(\"amount resumees : \"+ str(len(imported_data)))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{\"content\": \"Afreen Jamadar\\nActive member of IIIT Committee in Third year\\n\\nSangli, Maharashtra - Email me on Indeed: indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\\n\\nI wish to use my knowledge, skills and conceptual understanding to create excellent team\\nenvironments and work consistently achieving organization objectives believes in taking initiative\\nand work to excellence in my work.\\n\\nWORK EXPERIENCE\\n\\nActive member of IIIT Committee in Third year\\n\\nCisco Networking -  Kanpur, Uttar Pradesh\\n\\norganized by Techkriti IIT Kanpur and Azure Skynet.\\nPERSONALLITY TRAITS:\\n• Quick learning ability\\n• hard working\\n\\nEDUCATION\\n\\nPG-DAC\\n\\nCDAC ACTS\\n\\n2017\\n\\nBachelor of Engg in Information Technology\\n\\nShivaji University Kolhapur -  Kolhapur, Maharashtra\\n\\n2016\\n\\nSKILLS\\n\\nDatabase (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\\n\\nhttps://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\",\"annotation\":[{\"label\":[\"Email Address\"],\"points\":[{\"start\":1155,\"end\":1198,\"text\":\"indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\"}]},{\"label\":[\"Links\"],\"points\":[{\"start\":1143,\"end\":1239,\"text\":\"https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\"}]},{\"label\":[\"Skills\"],\"points\":[{\"start\":743,\"end\":1140,\"text\":\"Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\"}]},{\"label\":[\"Graduation Year\"],\"points\":[{\"start\":729,\"end\":732,\"text\":\"2016\"}]},{\"label\":[\"College Name\"],\"points\":[{\"start\":675,\"end\":702,\"text\":\"Shivaji University Kolhapur \"}]},{\"label\":[\"Degree\"],\"points\":[{\"start\":631,\"end\":672,\"text\":\"Bachelor of Engg in Information Technology\"}]},{\"label\":[\"Graduation Year\"],\"points\":[{\"start\":625,\"end\":629,\"text\":\"2017\\n\"}]},{\"label\":[\"College Name\"],\"points\":[{\"start\":614,\"end\":622,\"text\":\"CDAC ACTS\"}]},{\"label\":[\"Degree\"],\"points\":[{\"start\":606,\"end\":611,\"text\":\"PG-DAC\"}]},{\"label\":[\"Companies worked at\"],\"points\":[{\"start\":438,\"end\":453,\"text\":\"Cisco Networking\"}]},{\"label\":[\"Email Address\"],\"points\":[{\"start\":104,\"end\":147,\"text\":\"indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\"}]},{\"label\":[\"Location\"],\"points\":[{\"start\":62,\"end\":67,\"text\":\"Sangli\"}]},{\"label\":[\"Name\"],\"points\":[{\"start\":0,\"end\":13,\"text\":\"Afreen Jamadar\"}]}],\"extras\":null,\"metadata\":{\"first_done_at\":1527844872000,\"last_updated_at\":1537724086000,\"sec_taken\":0,\"last_updated_by\":\"BIQNZm4INNfvByMqkaVwVt6OZTv2\",\"status\":\"done\",\"evaluation\":\"CORRECT\"}}\n",
            "\n",
            "amount resumees : 701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I1ZSnIfOWLP_"
      },
      "source": [
        "Map the dataset to json"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "We0edT5BWRTv"
      },
      "source": [
        "import json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vI-fguXrWTvo"
      },
      "source": [
        "mapped_data = [ json.loads( datum ) for datum in imported_data  ]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yrwEGwLsMb6n"
      },
      "source": [
        "Now, the data are stored in __mapped_data__. __mapped_data__ is a list, and its entries are dictionaries.<br>\n",
        "__Task 2__: choose an entry of __mapped_data__, iterate over its keys, print the key and its corresponding value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "exSHAxQFYBbp",
        "outputId": "2230462d-0577-406c-cdf2-b3894d208b4f"
      },
      "source": [
        "#TODO choose an entry of mapped_data, iterate over its keys, print the key and its corresponding value\n",
        "#print(mapped_data[0][\"content\"])\n",
        "\n",
        "for key, value in mapped_data[0].items():\n",
        "  print(\"Key : \" + str(key) + \"; Value : \" + str(value))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key : content; Value : Afreen Jamadar\n",
            "Active member of IIIT Committee in Third year\n",
            "\n",
            "Sangli, Maharashtra - Email me on Indeed: indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\n",
            "\n",
            "I wish to use my knowledge, skills and conceptual understanding to create excellent team\n",
            "environments and work consistently achieving organization objectives believes in taking initiative\n",
            "and work to excellence in my work.\n",
            "\n",
            "WORK EXPERIENCE\n",
            "\n",
            "Active member of IIIT Committee in Third year\n",
            "\n",
            "Cisco Networking -  Kanpur, Uttar Pradesh\n",
            "\n",
            "organized by Techkriti IIT Kanpur and Azure Skynet.\n",
            "PERSONALLITY TRAITS:\n",
            "• Quick learning ability\n",
            "• hard working\n",
            "\n",
            "EDUCATION\n",
            "\n",
            "PG-DAC\n",
            "\n",
            "CDAC ACTS\n",
            "\n",
            "2017\n",
            "\n",
            "Bachelor of Engg in Information Technology\n",
            "\n",
            "Shivaji University Kolhapur -  Kolhapur, Maharashtra\n",
            "\n",
            "2016\n",
            "\n",
            "SKILLS\n",
            "\n",
            "Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\n",
            "ACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "TECHNICAL SKILLS:\n",
            "\n",
            "• Programming Languages: C, C++, Java, .net, php.\n",
            "• Web Designing: HTML, XML\n",
            "• Operating Systems: Windows […] Windows Server 2003, Linux.\n",
            "• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\n",
            "\n",
            "https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\n",
            "Key : annotation; Value : [{'label': ['Email Address'], 'points': [{'start': 1155, 'end': 1198, 'text': 'indeed.com/r/Afreen-Jamadar/8baf379b705e37c6'}]}, {'label': ['Links'], 'points': [{'start': 1143, 'end': 1239, 'text': 'https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN'}]}, {'label': ['Skills'], 'points': [{'start': 743, 'end': 1140, 'text': 'Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.'}]}, {'label': ['Graduation Year'], 'points': [{'start': 729, 'end': 732, 'text': '2016'}]}, {'label': ['College Name'], 'points': [{'start': 675, 'end': 702, 'text': 'Shivaji University Kolhapur '}]}, {'label': ['Degree'], 'points': [{'start': 631, 'end': 672, 'text': 'Bachelor of Engg in Information Technology'}]}, {'label': ['Graduation Year'], 'points': [{'start': 625, 'end': 629, 'text': '2017\\n'}]}, {'label': ['College Name'], 'points': [{'start': 614, 'end': 622, 'text': 'CDAC ACTS'}]}, {'label': ['Degree'], 'points': [{'start': 606, 'end': 611, 'text': 'PG-DAC'}]}, {'label': ['Companies worked at'], 'points': [{'start': 438, 'end': 453, 'text': 'Cisco Networking'}]}, {'label': ['Email Address'], 'points': [{'start': 104, 'end': 147, 'text': 'indeed.com/r/Afreen-Jamadar/8baf379b705e37c6'}]}, {'label': ['Location'], 'points': [{'start': 62, 'end': 67, 'text': 'Sangli'}]}, {'label': ['Name'], 'points': [{'start': 0, 'end': 13, 'text': 'Afreen Jamadar'}]}]\n",
            "Key : extras; Value : None\n",
            "Key : metadata; Value : {'first_done_at': 1527844872000, 'last_updated_at': 1537724086000, 'sec_taken': 0, 'last_updated_by': 'BIQNZm4INNfvByMqkaVwVt6OZTv2', 'status': 'done', 'evaluation': 'CORRECT'}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8gp7URulapTm"
      },
      "source": [
        "__Question 1__: What are the keys, and what information do these keys store?<br>\n",
        "There are 3 different keys: annotation, extras and metadata, where the annotations are the ground truth labels for the ML, extras is empty, and metadata holds information about updates of the informations\n",
        "\n",
        "__Task 3__: for each entry of __annotations__: iterate over the keys of this entry and print the key and the corresponding value."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K9WcXpq4bTee",
        "outputId": "8d814233-40e5-4295-f354-24ec9177ff79"
      },
      "source": [
        "# TODO for each entry of annotations: iterate over the keys of this entry and print the key and the corresponding value\n",
        "for item in mapped_data[0][\"annotation\"]:\n",
        "    print(\"Key : \" + str(item[\"label\"]) + \"; Value : \" + str(item[\"points\"]))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Key : ['Email Address']; Value : [{'start': 1155, 'end': 1198, 'text': 'indeed.com/r/Afreen-Jamadar/8baf379b705e37c6'}]\n",
            "Key : ['Links']; Value : [{'start': 1143, 'end': 1239, 'text': 'https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN'}]\n",
            "Key : ['Skills']; Value : [{'start': 743, 'end': 1140, 'text': 'Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.'}]\n",
            "Key : ['Graduation Year']; Value : [{'start': 729, 'end': 732, 'text': '2016'}]\n",
            "Key : ['College Name']; Value : [{'start': 675, 'end': 702, 'text': 'Shivaji University Kolhapur '}]\n",
            "Key : ['Degree']; Value : [{'start': 631, 'end': 672, 'text': 'Bachelor of Engg in Information Technology'}]\n",
            "Key : ['Graduation Year']; Value : [{'start': 625, 'end': 629, 'text': '2017\\n'}]\n",
            "Key : ['College Name']; Value : [{'start': 614, 'end': 622, 'text': 'CDAC ACTS'}]\n",
            "Key : ['Degree']; Value : [{'start': 606, 'end': 611, 'text': 'PG-DAC'}]\n",
            "Key : ['Companies worked at']; Value : [{'start': 438, 'end': 453, 'text': 'Cisco Networking'}]\n",
            "Key : ['Email Address']; Value : [{'start': 104, 'end': 147, 'text': 'indeed.com/r/Afreen-Jamadar/8baf379b705e37c6'}]\n",
            "Key : ['Location']; Value : [{'start': 62, 'end': 67, 'text': 'Sangli'}]\n",
            "Key : ['Name']; Value : [{'start': 0, 'end': 13, 'text': 'Afreen Jamadar'}]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6i-ZPKiyfyrt"
      },
      "source": [
        "__Question 2__: What did you learn about the __annotations__? Give an example.<br>\n",
        "The Keys \"Annotation\" are entity labels and they also hold the string start and end in the resumee and the according text: \"Key : ['Name']; Value : [{'start': 0, 'end': 13, 'text': 'Afreen Jamadar'}]\"\n",
        "\n",
        "__Task 4__: Complete the following code to map the __mapped_data__ to a format, from which Spacy can learn. Print the first converted resumee for inspection. Choose one resumee. For this resumee, print all the data in __entities__."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mzmu0XSOhybH",
        "outputId": "048d6070-8e0f-4c66-e58a-1337a80e8691"
      },
      "source": [
        "## data conversion method\n",
        "def convert_data(data):\n",
        "    \"\"\"\n",
        "    Creates NER training data in Spacy format from JSON dataset\n",
        "    Outputs the Spacy training data which can be used for Spacy training.\n",
        "    \"\"\"\n",
        "    text = data['content']\n",
        "    entities = []\n",
        "    if data['annotation'] is not None:\n",
        "        for annotation in data['annotation']:\n",
        "            # only a single point in text annotation.\n",
        "            point = annotation['points'][0]\n",
        "            labels = annotation['label']\n",
        "            # handle both list of labels or a single label.\n",
        "            if not isinstance(labels, list):\n",
        "                labels = [labels]\n",
        "            for label in labels:\n",
        "                # dataturks indices are both inclusive [start, end] but spacy is not [start, end)\n",
        "                entities.append((point['start'], point['end'] + 1, label))\n",
        "    return (text, {\"entities\": entities})\n",
        "   \n",
        "## TODO using a loop or list comprehension, convert each resume in mapped_data using the convert function above, \n",
        "## storing the result\n",
        "converted_resumes = [convert_data(entry) for entry in mapped_data]\n",
        "\n",
        "## TODO print the number of resumes in converted resumes \n",
        "print(len(converted_resumes))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "701\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2jO6WUBLiaD0",
        "outputId": "2afe7818-d23d-45dd-b67c-dca5b947d9be"
      },
      "source": [
        "# TODO print the first resumee for inspection\n",
        "print(converted_resumes[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "('Afreen Jamadar\\nActive member of IIIT Committee in Third year\\n\\nSangli, Maharashtra - Email me on Indeed: indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\\n\\nI wish to use my knowledge, skills and conceptual understanding to create excellent team\\nenvironments and work consistently achieving organization objectives believes in taking initiative\\nand work to excellence in my work.\\n\\nWORK EXPERIENCE\\n\\nActive member of IIIT Committee in Third year\\n\\nCisco Networking -  Kanpur, Uttar Pradesh\\n\\norganized by Techkriti IIT Kanpur and Azure Skynet.\\nPERSONALLITY TRAITS:\\n• Quick learning ability\\n• hard working\\n\\nEDUCATION\\n\\nPG-DAC\\n\\nCDAC ACTS\\n\\n2017\\n\\nBachelor of Engg in Information Technology\\n\\nShivaji University Kolhapur -  Kolhapur, Maharashtra\\n\\n2016\\n\\nSKILLS\\n\\nDatabase (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\\nACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\\n\\nADDITIONAL INFORMATION\\n\\nTECHNICAL SKILLS:\\n\\n• Programming Languages: C, C++, Java, .net, php.\\n• Web Designing: HTML, XML\\n• Operating Systems: Windows […] Windows Server 2003, Linux.\\n• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\\n\\nhttps://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN', {'entities': [(1155, 1199, 'Email Address'), (1143, 1240, 'Links'), (743, 1141, 'Skills'), (729, 733, 'Graduation Year'), (675, 703, 'College Name'), (631, 673, 'Degree'), (625, 630, 'Graduation Year'), (614, 623, 'College Name'), (606, 612, 'Degree'), (438, 454, 'Companies worked at'), (104, 148, 'Email Address'), (62, 68, 'Location'), (0, 14, 'Name')]})\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6FDv_kfXi4MF",
        "outputId": "b7e3fd5d-18b8-4fae-d170-7a67b1253e1b"
      },
      "source": [
        "# TODO choose one resumee. For this resumee, print all the data in entities. Use the dumps function from json.\n",
        "entityList = converted_resumes[0][1]\n",
        "print(entityList[\"entities\"])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[(1155, 1199, 'Email Address'), (1143, 1240, 'Links'), (743, 1141, 'Skills'), (729, 733, 'Graduation Year'), (675, 703, 'College Name'), (631, 673, 'Degree'), (625, 630, 'Graduation Year'), (614, 623, 'College Name'), (606, 612, 'Degree'), (438, 454, 'Companies worked at'), (104, 148, 'Email Address'), (62, 68, 'Location'), (0, 14, 'Name')]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lXx23PxAjPBj"
      },
      "source": [
        "__Task 5__: Explain the printout from above.<br>\n",
        "Spacy training format is consisting of a tuple with 2 elements: text, entities. Where the entities are the ground truth labels: startChar, endChar, label-Name\n",
        "\n",
        "__Task 6__: Since some resumees have no annotation, we want to filter these out. You can recognize these resumees by them having no entries in __entities__. Pick one of the remaining resumees, iterate over the items in __entitities__, print for each item the label and the corresponding text from the resumee."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8KjAdqTckp41"
      },
      "source": [
        "# TODO filter out the resumees whose entities have no entries.\n",
        "converted_complete_resumees = None\n",
        "\n",
        "def empty_entity_list(data):\n",
        "  entityList = data[1][\"entities\"]\n",
        "  if len(entityList) == 0:\n",
        "    return True\n",
        "  return False\n",
        "\n",
        "converted_complete_resumees = [data for data in converted_resumes if not empty_entity_list(data)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Al0x9iyBk-qs",
        "outputId": "5cac997e-9184-469a-ce06-6415a32fca96"
      },
      "source": [
        "print( len( converted_complete_resumees ) )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "690\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qys_4RJ6nCCj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c560a208-150e-4b16-e67f-68fd496eb4db"
      },
      "source": [
        "# TODO Now, pick one resumee from converted_complete_resumees, and iterate over the items in \n",
        "# entities. Print for each item the label and the corresponding text from the resumee.\n",
        "\n",
        "resume_entity = converted_complete_resumees[0][1] \n",
        "resume_text = converted_complete_resumees[0][0]\n",
        "for item in resume_entity[\"entities\"]:\n",
        "    print(\"Label : \" + str(item[2]) + \"; Value : \" + str(resume_text[item[0]:item[1]]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Label : Email Address; Value : indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\n",
            "Label : Links; Value : https://www.indeed.com/r/Afreen-Jamadar/8baf379b705e37c6?isid=rex-download&ikw=download-top&co=IN\n",
            "Label : Skills; Value : Database (Less than 1 year), HTML (Less than 1 year), Linux. (Less than 1 year), MICROSOFT\n",
            "ACCESS (Less than 1 year), MICROSOFT WINDOWS (Less than 1 year)\n",
            "\n",
            "ADDITIONAL INFORMATION\n",
            "\n",
            "TECHNICAL SKILLS:\n",
            "\n",
            "• Programming Languages: C, C++, Java, .net, php.\n",
            "• Web Designing: HTML, XML\n",
            "• Operating Systems: Windows […] Windows Server 2003, Linux.\n",
            "• Database: MS Access, MS SQL Server 2008, Oracle 10g, MySql.\n",
            "Label : Graduation Year; Value : 2016\n",
            "Label : College Name; Value : Shivaji University Kolhapur \n",
            "Label : Degree; Value : Bachelor of Engg in Information Technology\n",
            "Label : Graduation Year; Value : 2017\n",
            "\n",
            "Label : College Name; Value : CDAC ACTS\n",
            "Label : Degree; Value : PG-DAC\n",
            "Label : Companies worked at; Value : Cisco Networking\n",
            "Label : Email Address; Value : indeed.com/r/Afreen-Jamadar/8baf379b705e37c6\n",
            "Label : Location; Value : Sangli\n",
            "Label : Name; Value : Afreen Jamadar\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QJCOSsZJtDnA"
      },
      "source": [
        "__Question 3__: Are the labels unique? If the labels are not unique, does this make the data ambigious?<br>\n",
        "No there are some labels which are not unique, like Companies worked at, which can have multiple occurences in different resumees and furthermore, can occur more often in same resumee, if person has worked for more than one company. But this does not make the data ambigious, as those relations have to be learned.\n",
        "\n",
        "__Task 7__: Collect the names of all entities in __converted_complete_resumee__ dataset, and store these names in __all_labels__. Then iterate over the contents of __all_labels__, and store each name that does not appear in __unique_labels__ in __unique_labels__, so that __unique_labels__ contains each name that appears in __all_labels__, but only once."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i8N5z6OutflX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec1aea1a-2354-445d-83eb-8caae83e7959"
      },
      "source": [
        "# TODO Collect the names of all entities in converted_complete_resumee dataset, and store these names \n",
        "# in all_labels. Then iterate over the contents of all_labels, and store each name that does not appear \n",
        "# in unique_labels in unique_labels, so that unique_labels contains each name that appears in \n",
        "# all_labels, but only once.\n",
        "all_labels = []\n",
        "\n",
        "unique_labels = []\n",
        "\n",
        "for res in converted_complete_resumees:\n",
        "  entities = res[1][\"entities\"]\n",
        "  for e in entities:\n",
        "    label = e[2]\n",
        "    all_labels.append(label)\n",
        "\n",
        "unique_labels = list(set(all_labels))\n",
        "\n",
        "for item in unique_labels:\n",
        "  print( item )"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "projects\n",
            "Degree\n",
            "Links\n",
            "Graduation Year\n",
            "Email Address\n",
            "Location\n",
            "Companies worked at\n",
            "Designation\n",
            "UNKNOWN\n",
            "College\n",
            "Rewards and Achievements\n",
            "Years of Experience\n",
            "abc\n",
            "College Name\n",
            "Address\n",
            "links\n",
            "Certifications\n",
            "Can Relocate to\n",
            "Relocate to\n",
            "Name\n",
            "training\n",
            "Skills\n",
            "state\n",
            "des\n",
            "University\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxJ_ZC6Zv0q1"
      },
      "source": [
        "__Task 8__: Now choose three labels, on which you want to train your named entity recognition algorithm. You want to have for each label at least 300 documents."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KgZMpQTwiIu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f4c5feb-fa74-4b17-ee3e-7939cb798a42"
      },
      "source": [
        "## TODO store entity label names for the entities you want to work with in an array \n",
        "chosen_entity_label = [ \"Skills\", \"Companies worked at\", \"Degree\" ]\n",
        "## for each chosen entity label, count how many documents have a labeled entity for that label, and how many labeled entities total there are \n",
        "## for that entity\n",
        "for chosen in chosen_entity_label:\n",
        "    found_docs_with_entity = 0\n",
        "    entity_count = 0\n",
        "    for resume in converted_complete_resumees:\n",
        "        entity_list = resume[1][\"entities\"]\n",
        "        _,_,labels = zip(*entity_list)\n",
        "        if chosen in labels:\n",
        "            found_docs_with_entity+=1\n",
        "            entity_count+=len([l for l in labels if l == chosen])\n",
        "    print(\"Docs with {}: {}\".format(chosen,found_docs_with_entity))\n",
        "    print(\"Total count of {}: {}\".format(chosen,entity_count))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Docs with Skills: 536\n",
            "Total count of Skills: 2152\n",
            "Docs with Companies worked at: 627\n",
            "Total count of Companies worked at: 2830\n",
            "Docs with Degree: 606\n",
            "Total count of Degree: 1012\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}